\chapter{Einführungen}

\section{A-prior-Wahrscheinlichkeit}

Die A-prior-Wahrscheinlichkeit ist in den Naturwissenschaften der Wahrscheinlichkeitswert, der aufgrund von allgmemeinem Vorwissen über die Eigenschaften des Systems
(Ein Beispiel ist der Würfel, mit seinen symmetrischen Eigenschaften) gewonnen wird. Die A-prior-Wahrscheinlichkeiten sind die Grundvorraussetzungen
bei der Berechnung der bedingten Wahrscheinlichkeit eines zusammengesetzen Ereignisses und beim bayesschen Wahrscheinlichkeitsbegriff \footnote{to be done}.
Die älteste Methode für die Bestimmung von A-prior-Wahrscheinlichkeiten stammt von Laplace. Sofern es keinen keinen expliziten Grund gibt, die ursprünglich
offensichtliche Annahme zu ändern, wird allen Elementarereignissen die gleiche Wahrscheinlichkeit zugeordnet. \cite[S. 80f]{Pap:1995}

Nimmt man das oben genante Beispiel eines Würfels ergibt sich die folgende Wahrscheinlichkeitsverteilung:

\begin{itemize} 
    \item Zahl 1: Wahrscheinlichkeit = $\frac{1}{6}$
    \item Zahl 2: Wahrscheinlichkeit = $\frac{1}{6}$
    \item Zahl 3: Wahrscheinlichkeit = $\frac{1}{6}$
    \item Zahl 4: Wahrscheinlichkeit = $\frac{1}{6}$
    \item Zahl 5: Wahrscheinlichkeit = $\frac{1}{6}$
    \item Zahl 6: Wahrscheinlichkeit = $\frac{1}{6}$
\end{itemize}

Dies ist allerdings nur der Fall, solange man keinen Grund hat anzunehmen, dass der Würfel manipuliert sei. Es handelt sich also um Elementarereignisse, der
alle dieselbe Wahrscheinlichkeit zugeordnet sind.

\section{Satz von Bayes}

Der Satz von Bayes ist ein mathematischer Satz, der aus der Wahrscheinlichkeitstheorie stammt. Er beschreibt die Berechnung bedingter 
Wahrscheinlichkeiten\footnote{Die Wahrscheinlichkeit des Eintretens eines Ereignisses A unter der Bedingung, dass das Einteten eines anderen Ereignisses B bereits bekannt ist.}.
Der Satz ist nach dem englischen Mathematiker Thomas Bayes benannt und wird auch als Formel von Bayes oder als Bayes-Theorem bezeichnet. \cite[S.411f]{Papulla:2014}

\subsection{Formel}

Für zwei Ereignisse\footnote{Ein Ereignis ist in der Statistik ein Teil einer Menge von Ergebnissen eines Zufallexperiments, dem eine Wahrscheinlichkeit zugeordnet
werden kann.} \textit{A} und \textit{B} mit \textit{P(B) > 0} lässt sich die Wahrscheinlichkeit von \textit{A} unter der Bedingung, dass \textit{B} eingetreten
ist, durch die Wahrscheinlichkeit von \textit{B} unter der Bedingung, dass \textit{A} eingetreten ist, errechnen:

\begin{equation}
    P(G | B) = \frac{P(B | A) \cdot P(A)}{P(B)}
\end{equation}

Hierbei ist

\begin{itemize}
    \item \textit{P(A | B)} die bedingte Wahrscheinlichkeit des Ereignisses \textit{A} unter der Bedingung, dass \textit{B} eingetreten ist,
    \item \textit{P(B | A)} die bedingte Wahrscheinlichkeit des Ereignisses \textit{B} unter der Bedingung, dass \textit{A} eingetreten ist,
    \item \textit{P(A)} die A-prior-Wahrscheinlichkeit des Ereignisses \textit{A} und
    \item \textit{P(B)} die A-prior-Wahrscheinlichkeit des Ereignisses \textit{B}.
\end{itemize}

Bei endlich vielen Ereignissen lautet der Satz von Bayes:

Wenn \textit{$A_i, i = 1,..., N$} eine Zerlegung der Ergebnismenge in disjunkte Ereignisse ist, gilt für die A-posteriori-Wahrscheinlichkeit\footnote{TOBEDONE}
 \textit{$P(A_i | B)$}

\begin{equation}
    P(A_i | B) = \frac{P(B | A_i) \cdot P(A_i)}{P(B)} \underbrace{= \frac{P(B | A_i) \cdot P(A_i)}{\sum_{j = 1}^{N} P(B | A_j) \cdot P(A_j)}}_{Marginalisierung}
\end{equation}

Da ein Ereignis \textit{A} und sein Komplement \footnote{Komplement to be done} \textit{$A^c$} stets eine Zerlegung der Ergebnismenge darstellen, gilt insbesondere

\begin{equation}
    P(A | B) = \frac{P(B | A) \cdot P(A)}{P(B | A) \cdot P(A) + P(B | A^c) \cdot P(A^c)}
\end{equation}

\cite[S.411f]{Papulla:2014}
